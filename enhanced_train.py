"""
Enhanced Training Pipeline for Multiple Legal Datasets
Handles: Constitution, IPC, CPC, NIA, and IndicLegalQA (10K+ samples)
"""
import torch
import os
from enhanced_pretrain import enhanced_pretrain_gpt2
from enhanced_finetune import enhanced_finetune_gpt2

def main():
    """Enhanced training pipeline with multiple legal datasets"""
    print("ğŸ‡®ğŸ‡³ Enhanced LawGPT Training Pipeline - Multiple Legal Datasets")
    print("=" * 70)
    print("ğŸ“š Datasets included:")
    print("   â€¢ Indian Constitution (COI)")
    print("   â€¢ Indian Penal Code (IPC)")
    print("   â€¢ Code of Civil Procedure (CPC)")
    print("   â€¢ National Investigation Agency (NIA)")
    print("   â€¢ IndicLegalQA Dataset (10K+ Q&A pairs)")
    print("=" * 70)
    
    # Check CUDA availability
    if torch.cuda.is_available():
        print(f"âœ… CUDA Available: {torch.cuda.get_device_name(0)}")
        print(f"ğŸ”¥ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
        # Clear GPU cache
        torch.cuda.empty_cache()
    else:
        print("âš ï¸  No GPU available, using CPU (training will be slow)")
    
    print("\nğŸ¯ Training Pipeline:")
    print("1. Enhanced Continued Pretraining (941 samples)")
    print("2. Enhanced Supervised Fine-tuning (10,210 samples)")
    print("=" * 70)
    
    try:
        # Step 1: Enhanced Pretraining
        print("\nğŸ“– STEP 1: ENHANCED PRETRAINING")
        print("-" * 40)
        enhanced_pretrained_model_path = enhanced_pretrain_gpt2()
        print(f"âœ… Enhanced pretraining completed successfully!")
        
        # Clear GPU cache between training phases
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            print("ğŸ§¹ GPU cache cleared")
        
        # Step 2: Enhanced Fine-tuning
        print(f"\nğŸ¯ STEP 2: ENHANCED FINE-TUNING")
        print("-" * 40)
        enhanced_finetuned_model_path = enhanced_finetune_gpt2(enhanced_pretrained_model_path)
        print(f"âœ… Enhanced fine-tuning completed successfully!")
        
        # Final success message
        print("\nğŸ‰ ENHANCED TRAINING COMPLETED!")
        print("=" * 70)
        print("ğŸ“ Model Locations:")
        print(f"   ğŸ“š Enhanced Pretrained: {enhanced_pretrained_model_path}")
        print(f"   ğŸ¯ Enhanced Fine-tuned: {enhanced_finetuned_model_path}")
        print("\nğŸ“Š Dataset Summary:")
        print("   ğŸ”„ Pretraining: 941 samples (25x increase)")
        print("   ğŸ¯ Instruction: 10,210 samples (138x increase)")
        print("\nğŸ’¡ Next Steps:")
        print("   â€¢ Test with: python enhanced_inference.py")
        print("   â€¢ Compare with: python model_comparison.py")
        print("   â€¢ The model now understands:")
        print("     - Indian Constitution articles")
        print("     - Indian Penal Code sections")
        print("     - Civil Procedure Code")
        print("     - Legal case Q&A (10K+ examples)")
        
    except Exception as e:
        print(f"\nâŒ Enhanced training failed: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
